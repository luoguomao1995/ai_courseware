{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ee8ce2-4b03-4b57-b85d-b4fb6db26570",
   "metadata": {},
   "source": [
    "# ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbc193-f8fc-4e18-85e7-45d3e8a6383a",
   "metadata": {},
   "source": [
    "1. ç³»ç»Ÿæ€§ç»´æŠ¤ã€æµ‹è¯•ã€ç›‘æ§ä¸€ä¸ª LLM åº”ç”¨\n",
    "2. å­¦ä¹ ä½¿ç”¨ä¸»æµçš„å·¥å…·å®Œæˆä¸Šè¿°å·¥ä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2fb93-5991-48e1-898b-a48ebfda9481",
   "metadata": {},
   "source": [
    "## ç»´æŠ¤ä¸€ä¸ªç”Ÿäº§çº§çš„ LLM åº”ç”¨ï¼Œæˆ‘ä»¬éœ€è¦åšä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb536c0-3997-457a-b360-62fbbc910454",
   "metadata": {},
   "source": [
    "1. è°ƒè¯• Prompt\n",
    "2. Prompt ç‰ˆæœ¬ç®¡ç†\n",
    "3. æµ‹è¯•/éªŒè¯ç³»ç»Ÿçš„ç›¸å…³æŒ‡æ ‡\n",
    "4. æ•°æ®é›†ç®¡ç†\n",
    "5. å„ç§æŒ‡æ ‡ç›‘æ§ä¸ç»Ÿè®¡ï¼šè®¿é—®é‡ã€å“åº”æ—¶é•¿ã€Tokenè´¹ç­‰ç­‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579d2ef-95ed-4e05-a025-940434a88100",
   "metadata": {},
   "source": [
    "### é’ˆå¯¹ä»¥ä¸Šéœ€æ±‚ï¼Œæˆ‘ä»¬ä»‹ç»ä¸‰ä¸ªç”Ÿäº§çº§ LLM App ç»´æŠ¤å¹³å°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb8637-fd33-438c-bfba-5acc62ff8500",
   "metadata": {},
   "source": [
    "1. **LangSmith**: LangChain çš„å®˜æ–¹å¹³å°ï¼ŒSaaS æœåŠ¡ï¼Œéå¼€æºï¼›\n",
    "2. **LangFuse**: å¼€æº + SaaSï¼ŒLangSmith å¹³æ›¿ï¼Œå¯é›†æˆ LangChain ä¹Ÿå¯ç›´æ¥å¯¹æ¥ OpenAI APIï¼›\n",
    "3. **Prompt Flow**ï¼šå¾®è½¯å¼€å‘ï¼Œå¼€æº + Azure AIäº‘æœåŠ¡ï¼Œå¯é›†æˆ Semantic Kernelã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f2552-f3af-4484-91e3-3c2308c05921",
   "metadata": {},
   "source": [
    "## 1ã€LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f950af-34cd-43f1-a1a2-ed18d3743f1f",
   "metadata": {},
   "source": [
    "å¹³å°å…¥å£ï¼šhttps://www.langchain.com/langsmith\n",
    "\n",
    "æ–‡æ¡£åœ°å€ï¼šhttps://python.langchain.com/docs/langsmith/walkthrough\n",
    "\n",
    "å°†ä½ çš„ LangChain åº”ç”¨ä¸ LangSmith é“¾æ¥ï¼Œéœ€è¦ï¼š\n",
    "\n",
    "1. æ³¨å†Œè´¦å·ï¼Œå¹¶ç”³è¯·ä¸€ä¸ª`LANGCHAIN_API_KEY`\n",
    "2. åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®ä»¥ä¸‹å€¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77875bb-76ca-4737-afa9-5796064e6e10",
   "metadata": {},
   "source": [
    "```shell\n",
    "export LANGCHAIN_TRACING_V2=true\n",
    "export LANGCHAIN_PROJECT=YOUR_PROJECT_NAME #è‡ªå®šä¹‰é¡¹ç›®åç§°\n",
    "export LANGCHAIN_ENDPOINT=https://api.smith.langchain.com #LangSmithçš„æœåŠ¡ç«¯ç‚¹\n",
    "export LANGCHAIN_API_KEY=LANGCHAIN_API_KEY # LangChain API Key\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de823435-67b7-4f96-974a-4588fad8a1ef",
   "metadata": {},
   "source": [
    "3. ç¨‹åºä¸­çš„è°ƒç”¨å°†è‡ªåŠ¨è¢«è®°å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e99900-e48c-4817-a1d4-fe3a101c62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"agi_demo_hello_world\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\"ls__a5a4ca7a021342748af8127bb805ba0a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dddaf145-15f2-450e-903c-2de85d6aeb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello ä¸­å›½!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# å®šä¹‰è¯­è¨€æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# å®šä¹‰Promptæ¨¡æ¿\n",
    "prompt = PromptTemplate.from_template(\"Say hello to {input}!\")\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"input\":RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"ä¸­å›½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59edfa6-2282-48ee-9c97-7af6a2532ddf",
   "metadata": {},
   "source": [
    "<img src=\"langsmith-example.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31a3eb-9fbf-408c-b2fc-5b5f3cb16268",
   "metadata": {},
   "source": [
    "### 1.1ã€åŸºæœ¬åŠŸèƒ½\n",
    "\n",
    "1. Traces\n",
    "2. LLM Calls\n",
    "3. Monitor\n",
    "4. Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c59c7c0-9e49-4230-841c-900487b716cb",
   "metadata": {},
   "source": [
    "### 1.2ã€Dataset & Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ffe88-06b1-4dc0-8937-88b9477bba79",
   "metadata": {},
   "source": [
    "åœ¨äº§å“ä¸­ä½¿ç”¨ä¸€ä¸ª AI åŠŸèƒ½ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦ç³»ç»Ÿæ€§æµ‹è¯•å®ƒçš„èƒ½åŠ›æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daddedd-c3aa-410f-a4e4-b9d3e6a039ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eea81ac-a705-4447-9ced-228c93a5cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import WikipediaRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Answer user's question according to the context below. \n",
    "Be brief, answer in no more than 20 words.\n",
    "CONTEXT_START\n",
    "{context}\n",
    "CONTEXT_END\n",
    "\n",
    "USER QUESTION:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "# æ£€ç´¢ wikipedia\n",
    "retriever = WikipediaRetriever(top_k_results=3)\n",
    "\n",
    "def chain_constructor(retriever):\n",
    "    # å®šä¹‰è¯­è¨€æ¨¡å‹\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "    # å®šä¹‰Promptæ¨¡æ¿\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        prompt_template\n",
    "    )\n",
    "    \n",
    "    # å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    response_generator = (\n",
    "        #{\"context\":retriever,\"input\":RunnablePassthrough()}\n",
    "        prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    chain = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"input\") | retriever | (lambda docs: \"\\n\".join([doc.page_content for doc in docs])),\n",
    "            \"input\":  itemgetter(\"input\")\n",
    "        }\n",
    "        | response_generator\n",
    "    )\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead1e1d-b602-4af9-a249-19131dd48554",
   "metadata": {},
   "source": [
    "ç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬éœ€è¦å‡†å¤‡ä¸€ä¸ªæ•°æ®é›†ï¼ŒåŒ…å«è¾“å…¥ä¸é¢„æœŸè¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb67c3b-c62c-446c-98f6-2dd93c866e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "qa_pairs = []\n",
    "with open('example_dataset.jsonl','r',encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        example = json.loads(line.strip())\n",
    "        qa_pairs.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e978a2d-74cd-4b9c-a3cb-18f81b091c67",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "[Errno 400 Client Error: Bad Request for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langsmith/utils.py:83\u001b[0m, in \u001b[0;36mraise_for_status_with_text\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m Client()\n\u001b[1;32m      5\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwiki_qa_dataset_demo_100\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#æ•°æ®é›†åç§°\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mä¸€ä¸ªæ•°æ®é›†æ ·ä¾‹ï¼Œä»wiki_qa benchmarkä¸­æŠ½å–çš„100æ¡é—®ç­”å¯¹\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#æ•°æ®é›†æè¿°\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m qa_pairs:\n\u001b[1;32m     13\u001b[0m     client\u001b[38;5;241m.\u001b[39mcreate_example(\n\u001b[1;32m     14\u001b[0m         inputs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]}, outputs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]}, dataset_id\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m     15\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langsmith/client.py:1282\u001b[0m, in \u001b[0;36mClient.create_dataset\u001b[0;34m(self, dataset_name, description, data_type)\u001b[0m\n\u001b[1;32m   1272\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ls_schemas\u001b[38;5;241m.\u001b[39mDatasetCreate(\n\u001b[1;32m   1273\u001b[0m     name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m   1274\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[1;32m   1275\u001b[0m     data_type\u001b[38;5;241m=\u001b[39mdata_type,\n\u001b[1;32m   1276\u001b[0m )\n\u001b[1;32m   1277\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1279\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_headers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m   1280\u001b[0m     data\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[1;32m   1281\u001b[0m )\n\u001b[0;32m-> 1282\u001b[0m \u001b[43mls_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas\u001b[38;5;241m.\u001b[39mDataset(\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[1;32m   1285\u001b[0m     _host_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host_url,\n\u001b[1;32m   1286\u001b[0m     _tenant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tenant_id(),\n\u001b[1;32m   1287\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langsmith/utils.py:85\u001b[0m, in \u001b[0;36mraise_for_status_with_text\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     83\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHTTPError\u001b[0m: [Errno 400 Client Error: Bad Request for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"wiki_qa_dataset_demo_100\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name, #æ•°æ®é›†åç§°\n",
    "    description=\"ä¸€ä¸ªæ•°æ®é›†æ ·ä¾‹ï¼Œä»wiki_qa benchmarkä¸­æŠ½å–çš„100æ¡é—®ç­”å¯¹\", #æ•°æ®é›†æè¿°\n",
    ")\n",
    "\n",
    "for example in qa_pairs:\n",
    "    client.create_example(\n",
    "        inputs={\"input\": example['question']}, outputs={\"output\": example['answer']}, dataset_id=dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f473e5-3873-42d0-b900-f0d9cea94412",
   "metadata": {},
   "source": [
    "ç¬¬äºŒæ­¥ï¼Œæˆ‘ä»¬å®šä¹‰è¯„ä¼°å‡½æ•°ï¼Œç”¨äºæ•°å€¼åŒ–çš„è¯„ä¼°æ¨¡å‹çš„å®é™…è¾“å‡ºä¸é¢„æœŸè¾“å‡ºä¹‹é—´çš„å·®è·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3813b43c-7ecd-46e3-9a2c-9b880bfea413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import EvaluatorType\n",
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    # è¯„ä¼°å™¨ï¼Œå¯å¤šé€‰\n",
    "    evaluators=[\n",
    "        # æ ¹æ®ç­”æ¡ˆåˆ¤æ–­å›å¤æ˜¯å¦\"Correct\"\n",
    "        EvaluatorType.QA,\n",
    "    ],\n",
    "    # å¯è¿½åŠ è‡ªå®šè¯„ä¼°æ ‡å‡†\n",
    "    custom_evaluators=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f2e89-0bc6-41df-b5b4-7fa938639795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'AGIClass_LangChain_WikiQA_Project-d37fcdde' at:\n",
      "https://smith.langchain.com/o/97b8262a-9ab9-4b43-afeb-21ea05a90ba7/projects/p/32d10247-25be-49e5-8d83-619e0ea36228?eval=true\n",
      "\n",
      "View all tests for Dataset wiki_qa_dataset_demo_100 at:\n",
      "https://smith.langchain.com/o/97b8262a-9ab9-4b43-afeb-21ea05a90ba7/datasets/e08eb251-fd32-4fe4-93bc-95fcd30c7167\n",
      "[------------------------------------------------->] 99/100"
     ]
    }
   ],
   "source": [
    "from langchain.smith import (\n",
    "    arun_on_dataset,\n",
    "    run_on_dataset,\n",
    ")\n",
    "from uuid import uuid4\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "chain = chain_constructor(retriever)\n",
    "\n",
    "chain_results = await arun_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    "    client=client,\n",
    "    project_name=f\"AGIClass_LangChain_WikiQA_Project-{unique_id}\",\n",
    "    tags=[\n",
    "        \"testing-agiclass-demo\",\n",
    "        \"2023-11-30\",\n",
    "    ],  # å¯é€‰ï¼Œè‡ªå®šä¹‰çš„æ ‡è¯†\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990c519-5615-4a53-9ca9-4e9bd7885ff9",
   "metadata": {},
   "source": [
    "### 1.3ã€è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195f62cc-43ae-4120-9008-a2ac456cfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import StringEvaluator\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import re\n",
    "from typing import Optional, Any\n",
    "\n",
    "class BleuEvaluator(StringEvaluator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def requires_input(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def requires_reference(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def evaluation_name(self) -> str:\n",
    "        return \"bleu_score\"\n",
    "\n",
    "    def _tokenize(self,sentence):\n",
    "        # æ­£åˆ™è¡¨è¾¾å¼å®šä¹‰äº†è¦å»é™¤çš„æ ‡ç‚¹ç¬¦å·\n",
    "        return re.sub(r'[^\\w\\s]', '', sentence.lower()).split()\n",
    "    \n",
    "    def _evaluate_strings(\n",
    "        self,\n",
    "        prediction: str,\n",
    "        input: Optional[str] = None,\n",
    "        reference: Optional[str] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> dict:\n",
    "        bleu_score = sentence_bleu(\n",
    "            [self._tokenize(reference)], \n",
    "            self._tokenize(prediction), \n",
    "            smoothing_function=SmoothingFunction().method3\n",
    "        )\n",
    "        return {\"score\": bleu_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc5d4a3b-8cbd-4f86-b079-11e812204b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'AGIClass_LangChain_Custom_Project-2b31e247' at:\n",
      "https://smith.langchain.com/o/97b8262a-9ab9-4b43-afeb-21ea05a90ba7/projects/p/9f795ab0-376c-48c4-b3ce-37cefef756dd?eval=true\n",
      "\n",
      "View all tests for Dataset wiki_qa_dataset_demo_100 at:\n",
      "https://smith.langchain.com/o/97b8262a-9ab9-4b43-afeb-21ea05a90ba7/datasets/e08eb251-fd32-4fe4-93bc-95fcd30c7167\n",
      "[------------------------------------------------->] 100/100"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from langchain.smith import (\n",
    "    arun_on_dataset,\n",
    "    run_on_dataset,\n",
    ")\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    # è‡ªå®šä¹‰çš„BLEU SCOREè¯„ä¼°å™¨\n",
    "    custom_evaluators=[BleuEvaluator()],\n",
    ")\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "chain = chain_constructor(retriever)\n",
    "\n",
    "chain_results = await arun_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    "    client=client,\n",
    "    project_name=f\"AGIClass_LangChain_Custom_Project-{unique_id}\",\n",
    "    tags=[\n",
    "        \"testing-agiclass-demo\",\n",
    "        \"2023-11\",\n",
    "    ],  # å¯é€‰ï¼Œè‡ªå®šä¹‰çš„æ ‡è¯†\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8f7ea-c259-4274-9311-44f8014bf92a",
   "metadata": {},
   "source": [
    "**é¢å¤–çŸ¥è¯†**: BLEU Score\n",
    "\n",
    "ä¼ ç»ŸNLPä¸­ï¼Œå¯¹æœºå™¨ç¿»è¯‘æˆ–æ–‡æœ¬ç”Ÿæˆç±»æ¨¡å‹æ•ˆæœçš„è‡ªåŠ¨è¯„ä¼°çš„å¸¸ç”¨æ–¹æ³•ä¹‹ä¸€ï¼ŒåŸç†å¦‚ä¸‹ï¼š\n",
    "  - è®¡ç®—è¾“å‡ºä¸å‚ç…§å¥ä¹‹é—´çš„ n-gram å‡†ç¡®ç‡ï¼ˆn=1...4ï¼‰\n",
    "  - å¯¹çŸ­è¾“å‡ºåšæƒ©ç½š\n",
    "  - åœ¨æ•´ä¸ªæµ‹è¯•é›†ä¸Šå¹³å‡ä¸‹è¿°å€¼\n",
    "\n",
    "$\\mathrm{BLEU}_4=\\min\\left(1,\\frac{output-length}{reference-length}\\right)\\left(\\prod_{i=1}^4 precision_i\\right)^{\\frac{1}{4}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858919a-2a93-47b3-a375-b4ee9dff056f",
   "metadata": {},
   "source": [
    "## 2ã€è¯´è¯´æ–‡æœ¬ç”Ÿæˆå¸¸ç”¨çš„è¯„ä¼°æ–¹æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883cb589-68a0-4cb0-b31c-505ae347b0e1",
   "metadata": {},
   "source": [
    "å‡è®¾æ–‡æœ¬ç”Ÿæˆé—®é¢˜ï¼Œæˆ‘ä»¬æœ‰æˆ–æ²¡æœ‰å‚è€ƒç­”æ¡ˆ reference æ—¶ï¼Œ\n",
    "\n",
    "æ€ä¹ˆè¯„ä¼°æ¨¡å‹ç”Ÿæˆçš„ç»“æœçš„ä¼˜åŠ£ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28e3e7-7303-454f-a259-0b8f49b29b13",
   "metadata": {},
   "source": [
    "### 2.1ã€åŸºäºå¤§æ¨¡å‹æœ¬èº«åšè¯„ä¼°\n",
    "\n",
    "https://docs.smith.langchain.com/evaluation/evaluator-implementations\n",
    "\n",
    "1. æ­£ç¡®æ€§ï¼ˆCorrectnessï¼‰ï¼šç”¨ LLM åˆ¤æ–­ç»™å®šçœŸå®ç­”æ¡ˆçš„å‰æä¸‹ï¼Œæ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26837e8-cc42-4449-9bb1-a0bfe6ee5f5f",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_PROMPT_TEMPLATE = \"\"\"You are an expert professor specialized in grading students' answers to questions.\n",
    "You are grading the following question:\n",
    "{query}\n",
    "Here is the real answer:\n",
    "{answer}\n",
    "You are grading the following predicted answer:\n",
    "{result}\n",
    "Respond with CORRECT or INCORRECT:\n",
    "Grade:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\", \"result\"], template=_PROMPT_TEMPLATE\n",
    ")\n",
    "eval_llm = ChatAnthropic(temperature=0.0)\n",
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        RunEvalConfig.QA(llm=eval_llm, prompt=PROMPT),\n",
    "        RunEvalConfig.ContextQA(llm=eval_llm),\n",
    "        RunEvalConfig.CoTQA(llm=eval_llm),\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970661a2-8d55-4213-b2b2-b701f0b28106",
   "metadata": {},
   "source": [
    "2. ç¬¦åˆæ ‡å‡†ï¼ˆCriteriaï¼‰ï¼šæ— å‚è€ƒç­”æ¡ˆæ—¶ï¼Œåˆ¤æ–­è¾“å‡ºæ˜¯å¦ç¬¦åˆç‰¹å®šæ ‡å‡†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58202832-a597-448c-9e3f-8062dbde7f87",
   "metadata": {},
   "source": [
    "```python\n",
    "from langsmith import Client\r\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\r\n",
    "\r\n",
    "evaluation_config = RunEvalConfig(\r\n",
    "    evaluators=[\r\n",
    "        # You can define an arbitrary criterion as a key: value pair in the criteria dict\r\n",
    "        RunEvalConfig.Criteria({\"creativity\": \"Is this submission creative, imaginative, or novel?\"}),\r\n",
    "        # We provide some simple default criteria like \"conciseness\" you can use as well\r\n",
    "        RunEvalConfig.Criteria(\"conciseness\"),\r\n",
    "    ]\r\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4be210-27fe-4e00-8254-515bb9ef0a18",
   "metadata": {},
   "source": [
    "3. æœ‰å¸®åŠ©ï¼ˆHelpfulnessï¼‰ï¼šæ ¹æ®å‚è€ƒç­”æ¡ˆåˆ¤æ–­æ¨¡å‹è¾“å‡ºæ˜¯å¦æœ‰å¸®åŠ©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0d475-9c08-4bca-a4bb-6f31958d6087",
   "metadata": {},
   "source": [
    "```python\n",
    "from langsmith import Client\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        # You can define an arbitrary criterion as a key: value pair in the criteria dict\n",
    "        RunEvalConfig.LabeledCriteria(\n",
    "            {\n",
    "                \"helpfulness\": (\n",
    "                    \"Is this submission helpful to the user,\"\n",
    "                    \" taking into account the correct reference answer?\"\n",
    "                )\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74fcf4-d84c-4b30-9858-02c5ddd45e7a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>æ­¤ç±»æ–¹æ³•ï¼Œå¯¹äºç”¨äºè¯„ä¼°çš„ LLM è‡ªèº«èƒ½åŠ›æœ‰è¦æ±‚ã€‚éœ€æ ¹æ®å…·ä½“æƒ…å†µé€‰æ‹©ä½¿ç”¨ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2eec79-5483-4ccb-8ff5-6fcdc8dc148b",
   "metadata": {},
   "source": [
    "### 2.2ã€ä¸€äº›ç»å…¸ NLP çš„è¯„æµ‹æ–¹æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a49ec-58ff-4d85-8f89-67c932b59b80",
   "metadata": {},
   "source": [
    "1. **ç¼–è¾‘è·ç¦»**ï¼šä¹Ÿå«è±æ–‡æ–¯å¦è·ç¦»(Levenshtein),æ˜¯é’ˆå¯¹äºŒä¸ªå­—ç¬¦ä¸²çš„å·®å¼‚ç¨‹åº¦çš„é‡åŒ–é‡æµ‹ï¼Œé‡æµ‹æ–¹å¼æ˜¯çœ‹è‡³å°‘éœ€è¦å¤šå°‘æ¬¡çš„å¤„ç†æ‰èƒ½å°†ä¸€ä¸ªå­—ç¬¦ä¸²å˜æˆå¦ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚\n",
    "   - å…·ä½“è®¡ç®—è¿‡ç¨‹æ˜¯ä¸€ä¸ªåŠ¨æ€è§„åˆ’ç®—æ³•ï¼šhttps://zhuanlan.zhihu.com/p/164599274\n",
    "   - è¡¡é‡ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼åº¦æ—¶ï¼Œå¯ä»¥ä»¥è¯ä¸ºå•ä½è®¡ç®—\n",
    "2. **BLEU Score**:\n",
    "   - è®¡ç®—è¾“å‡ºä¸å‚ç…§å¥ä¹‹é—´çš„ n-gram å‡†ç¡®ç‡ï¼ˆn=1...4ï¼‰\n",
    "   - å¯¹çŸ­è¾“å‡ºåšæƒ©ç½š\n",
    "   - åœ¨æ•´ä¸ªæµ‹è¯•é›†ä¸Šå¹³å‡ä¸‹è¿°å€¼\n",
    "3. **Rouge Score**:\n",
    "   - Rouge-Nï¼šå°†æ¨¡å‹ç”Ÿæˆçš„ç»“æœå’Œæ ‡å‡†ç»“æœæŒ‰ N-gram æ‹†åˆ†åï¼Œåªè®¡ç®—å¬å›ç‡ï¼›\n",
    "   - Rouge-L: åˆ©ç”¨äº†æœ€é•¿å…¬å…±å­åºåˆ—ï¼ˆLongest Common Sequenceï¼‰ï¼Œè®¡ç®—ï¼š$P=\\frac{LCS(c,r)}{len(c)}$, $R=\\frac{LCS(c,r)}{len(r)}$, $F=\\frac{(1+\\beta^2)PR}{R+\\beta^2P}$\n",
    "   - å‡½æ•°åº“ï¼šhttps://pypi.org/project/rouge-score/\n",
    "   - å¯¹æ¯” BLEU ä¸ ROUGEï¼š\n",
    "     - BLEU èƒ½è¯„ä¼°æµç•…åº¦ï¼Œä½†æŒ‡æ ‡åå‘äºè¾ƒçŸ­çš„ç¿»è¯‘ç»“æœï¼ˆbrevity penalty æ²¡æœ‰æƒ³è±¡ä¸­é‚£ä¹ˆå¼ºï¼‰\n",
    "     - ROUGE ä¸ç®¡æµç•…åº¦ï¼Œæ‰€ä»¥åªé€‚åˆæ·±åº¦å­¦ä¹ çš„ç”Ÿæˆæ¨¡å‹ï¼šç»“æœéƒ½æ˜¯æµç•…çš„å‰æä¸‹ï¼ŒROUGE ååº”å‚ç…§å¥ä¸­å¤šå°‘å†…å®¹è¢«ç”Ÿæˆçš„å¥å­åŒ…å«ï¼ˆå¬å›ï¼‰\n",
    "5. **METEOR**: å¦ä¸€ä¸ªä»æœºå™¨ç¿»è¯‘é¢†åŸŸå€Ÿé‰´çš„æŒ‡æ ‡ã€‚ä¸ BLEU ç›¸æ¯”ï¼ŒMETEOR è€ƒè™‘äº†æ›´å¤šçš„å› ç´ ï¼Œå¦‚åŒä¹‰è¯åŒ¹é…ã€è¯å¹²åŒ¹é…ã€è¯åºç­‰ï¼Œå› æ­¤å®ƒé€šå¸¸è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªæ›´å…¨é¢çš„è¯„ä»·æŒ‡æ ‡ã€‚\n",
    "   - å¯¹è¯­è¨€å­¦å’Œè¯­ä¹‰è¯è¡¨æœ‰ä¾èµ–ï¼Œæ‰€ä»¥å¯¹è¯­è¨€ä¾èµ–å¼ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c4c3d-eb17-420e-af3e-23b9e2e89752",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>æ­¤ç±»æ–¹æ³•å¸¸ç”¨äºå¯¹æ–‡æœ¬ç”Ÿæˆæ¨¡å‹çš„è‡ªåŠ¨åŒ–è¯„ä¼°ã€‚å®é™…ä½¿ç”¨ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸æ›´å…³æ³¨ç›¸å¯¹å˜åŒ–è€Œä¸æ˜¯ç»å¯¹å€¼ï¼ˆè°ƒä¼˜è¿‡ç¨‹ä¸­æŒ‡æ ‡æ˜¯ä¸æ˜¯åœ¨å˜å¥½ï¼‰ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2880a7-409b-405f-b202-c1e6206603d0",
   "metadata": {},
   "source": [
    "## 3ã€LangFuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de6111-677f-4599-a342-9501cc756404",
   "metadata": {},
   "source": [
    "åŠŸèƒ½ä¸ LangSmith åŸºæœ¬é‡åˆï¼Œå¼€æºï¼Œæ”¯æŒ LangChain é›†æˆæˆ–åŸç”Ÿ OpenAI API é›†æˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681acec-6906-4490-95a8-3717130ce073",
   "metadata": {},
   "source": [
    "<img src=\"langfuse.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c4550-2be4-4989-81fc-40a1539fdb97",
   "metadata": {},
   "source": [
    "1. é€šè¿‡å®˜æ–¹äº‘æœåŠ¡ä½¿ç”¨ï¼š\n",
    "   - æ³¨å†Œ: cloud.langfuse.com\n",
    "   - åˆ›å»º API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe54f6c-cc98-494f-b5c4-d9c125564d27",
   "metadata": {},
   "source": [
    "```sh\n",
    "LANGFUSE_SECRET_KEY=\"sk-lf-...\"\n",
    "LANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b049b1e6-2e06-439c-bcf8-c776f6dd5d32",
   "metadata": {},
   "source": [
    "2. é€šè¿‡ Docker æœ¬åœ°éƒ¨ç½²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9fbe43-94fc-4f9f-be9c-190580219940",
   "metadata": {},
   "source": [
    "```sh\n",
    "# Clone repository\n",
    "git clone https://github.com/langfuse/langfuse.git\n",
    "cd langfuse\n",
    " \n",
    "# Run server and db\n",
    "docker compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75383b1-fa32-4456-8c58-9ebdd6cf841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33e0d7-682a-4eb7-97be-52f98bfe0055",
   "metadata": {},
   "source": [
    "### 3.1ã€æ›¿æ¢ OpenAI å®¢æˆ·ç«¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a616c4-a9e1-434d-bebe-6748fca8d5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langfuse.openai import openai\n",
    "import os\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "  name=\"test-chat\",\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸ªæµ‹è¯•ç‰ˆæœºå™¨äººã€‚\"},\n",
    "      {\"role\": \"user\", \"content\": \"å¯¹æˆ‘è¯´'Hello, World!'\"}],\n",
    "  temperature=0,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6f5e7-2b9f-4c36-ad7e-ad4c88c07ed4",
   "metadata": {},
   "source": [
    "### 3.2ã€é€šè¿‡ LangChain çš„å›è°ƒé›†æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c47782b-9b28-4490-907a-0aa54f0b3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "handler = CallbackHandler(\n",
    "    os.getenv(\"LANGFUSE_PUBLIC_KEY\"), \n",
    "    os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee41e249-1151-440b-bba0-334cd024b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain.chat_models import ErnieBotChat\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "baidu_model = ErnieBotChat()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"Say hello to {input}!\") \n",
    "])\n",
    "\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"input\":RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | baidu_model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2a71703-76d6-450f-9a1c-e0bca46ddde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:langfuse:'model_name'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/callback.py\", line 522, in __on_llm_action\n",
      "    model_name = kwargs[\"invocation_params\"][\"model_name\"]\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
      "KeyError: 'model_name'\n",
      "ERROR:langfuse:run not found\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/callback.py\", line 593, in on_llm_end\n",
      "    raise Exception(\"run not found\")\n",
      "Exception: run not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'æ–‡å¿ƒ (wenhunjing) æ˜¯ä¸ªä»€ä¹ˆäº§å“/ç³»ç»Ÿå‘¢ï¼Ÿå®ƒæœ‰ç€ä»€ä¹ˆæ ·çš„ç‰¹ç‚¹å’Œä¼˜åŠ¿ï¼Ÿæ‚¨å¯ä»¥å°è¯•ä¸æˆ‘åˆ†äº«æ›´å¤šå…³äºæ–‡å¿ƒç³»ç»Ÿæˆ–è€…ç›¸å…³æ–¹é¢çš„ä¿¡æ¯ï¼Œæˆ‘å¾ˆä¹æ„å°è¯•å¸®åŠ©æ‚¨è§£ç­”å…³äºæ–‡å¿ƒçš„å„ç§é—®é¢˜ã€‚'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"æ–‡å¿ƒ\", config={\"callbacks\":[handler]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab4c61-9b5f-4861-aa74-a141f69947aa",
   "metadata": {},
   "source": [
    "### 3.3ã€æ•°æ®é›†ä¸æµ‹è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c1f87-38f9-4388-a414-5e7e2c9b3084",
   "metadata": {},
   "source": [
    "1. åˆ›å»ºæ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef67abc0-09d9-4548-92e8-158ed23f77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "qa_pairs = []\n",
    "with open('example_dataset.jsonl','r',encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        example = json.loads(line.strip())\n",
    "        qa_pairs.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156368ef-50aa-449f-922b-5a7ffd73f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.model import CreateDatasetRequest, CreateDatasetItemRequest\n",
    " \n",
    "# init\n",
    "langfuse = Langfuse()\n",
    "\n",
    "langfuse.create_dataset(CreateDatasetRequest(name=\"wiki_qa-20\"));\n",
    "\n",
    "for item in qa_pairs[:20]:\n",
    "  langfuse.create_dataset_item(\n",
    "    CreateDatasetItemRequest(\n",
    "        dataset_name=\"wiki_qa-20\",\n",
    "        # any python object or value\n",
    "        input=item[\"question\"],\n",
    "        # any python object or value, optional\n",
    "        expected_output=item[\"answer\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d43ff-fef4-4de8-bc37-ae01911561e0",
   "metadata": {},
   "source": [
    "2. å®šä¹‰è¯„ä¼°å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6155790-14c6-4931-b8c1-1c8de93538f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import re\n",
    "\n",
    "def bleu_score(output, expected_output):\n",
    "    def _tokenize(sentence):\n",
    "        # æ­£åˆ™è¡¨è¾¾å¼å®šä¹‰äº†è¦å»é™¤çš„æ ‡ç‚¹ç¬¦å·\n",
    "        return re.sub(r'[^\\w\\s]', '', sentence.lower()).split()\n",
    "    \n",
    "    return sentence_bleu(\n",
    "        [_tokenize(expected_output)], \n",
    "        _tokenize(output), \n",
    "        smoothing_function=SmoothingFunction().method3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c38fc-12d6-4696-b7cc-5f6a0f4dcae3",
   "metadata": {},
   "source": [
    "3. å®šä¹‰ Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79693294-b473-43c0-84ab-424f40531997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import WikipediaRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Answer user's question according to the context below. \n",
    "Be brief, answer in no more than 20 words.\n",
    "CONTEXT_START\n",
    "{context}\n",
    "CONTEXT_END\n",
    "\n",
    "USER QUESTION:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# å®šä¹‰è¯­è¨€æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# å®šä¹‰Promptæ¨¡æ¿\n",
    "prompt = PromptTemplate.from_template(\n",
    "    prompt_template\n",
    ")\n",
    "\n",
    "# æ£€ç´¢ wikipedia\n",
    "retriever = WikipediaRetriever(top_k_results=1)\n",
    "\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "parser = StrOutputParser()\n",
    "\n",
    "wiki_qa_chain = (\n",
    "    {\n",
    "        \"context\": retriever, \n",
    "        \"input\": RunnablePassthrough()\n",
    "    } \n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0a472-5af3-4904-85d5-ad66c5e9a7f2",
   "metadata": {},
   "source": [
    "4. è¿è¡Œæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad90f27-5aab-423a-96e8-1dc73a903cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]ERROR:langchain.callbacks.tracers.langchain:Authentication failed for https://api.smith.langchain.com/runs/64d5422b-c40f-4c93-8b8b-a98ed0a9e266. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/64d5422b-c40f-4c93-8b8b-a98ed0a9e266', '{\"detail\":\"Invalid auth\"}')\n",
      "ERROR:langchain.callbacks.tracers.langchain:Authentication failed for https://api.smith.langchain.com/runs. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs', '{\"detail\":\"Invalid auth\"}')\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:06<00:00,  3.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from langfuse.client import CreateScore\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset = langfuse.get_dataset(\"wiki_qa-20\")\n",
    "\n",
    "for item in tqdm(dataset.items):\n",
    "    handler = item.get_langchain_handler(run_name=\"test_wiki_qa-20\")\n",
    "\n",
    "    output = wiki_qa_chain.invoke(item.input, config={\"callbacks\":[handler]})\n",
    "    \n",
    "    handler.rootSpan.score(CreateScore(\n",
    "      name=\"bleu_score\",\n",
    "      value=bleu_score(output, item.expected_output)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0559b9-2baa-4508-a9a1-c069f7714fc0",
   "metadata": {},
   "source": [
    "### 3.4ã€åŸºäº LLM çš„æµ‹è¯•æ–¹æ³•\n",
    "\n",
    "LangFuse é›†æˆäº†ä¸€äº›åŸç”Ÿçš„åŸºäº LLM çš„è‡ªåŠ¨æµ‹è¯•æ ‡å‡†ã€‚\n",
    "\n",
    "å…·ä½“å‚è€ƒï¼šhttps://langfuse.com/docs/scores/model-based-evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8f664-41a2-41f2-8b00-73bd0abf27ef",
   "metadata": {},
   "source": [
    "## 4ã€Prompt Flow\n",
    "\n",
    "é¡¹ç›®åœ°å€ https://github.com/microsoft/promptflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f43012-06b6-42d7-a7c5-766f90bf8840",
   "metadata": {},
   "source": [
    "### 4.1ã€å®‰è£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb12a0-3f01-49bf-aaac-d86a93beb665",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install promptflow promptflow-tools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8ae3f-b928-4f78-9e25-47033a2b63fd",
   "metadata": {},
   "source": [
    "### 4.2ã€å‘½ä»¤è¡Œè¿è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edaba2-12f6-4414-8d32-b98493a8793e",
   "metadata": {},
   "source": [
    "```sh\n",
    "pf flow init --flow ./my_chatbot --type chat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22b652-e67d-41bb-bc7c-0bdb94e475e4",
   "metadata": {},
   "source": [
    "### 4.3ã€VSCode æ’ä»¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c5ce9-292c-43b0-ab04-81ba5d0eae68",
   "metadata": {},
   "source": [
    "https://marketplace.visualstudio.com/items?itemName=prompt-flow.prompt-flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85434c-d9b1-4e68-9050-690db2589a9a",
   "metadata": {},
   "source": [
    "<img src=\"vsc.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1f7b8-e7da-4c80-887c-44d4ad89478f",
   "metadata": {},
   "source": [
    "### 4.4ã€ä¸ Semantic Kernel ç»“åˆä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cf220-934e-4e11-8fc0-bea8604a38b0",
   "metadata": {},
   "source": [
    "<æ¼”ç¤º>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58790105-fafd-4a07-afab-7ff72fb0c4af",
   "metadata": {},
   "source": [
    "Azureäº‘æœåŠ¡ï¼šhttps://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/get-started-prompt-flow?view=azureml-api-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e365c65-9d5a-4fba-8d9d-b1be247f90c2",
   "metadata": {},
   "source": [
    "## æ€»ç»“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881722dc-400a-451a-abbf-4324a0a5c2db",
   "metadata": {},
   "source": [
    "ç®¡ç†ä¸€ä¸ª LLM åº”ç”¨çš„å…¨ç”Ÿå‘½å‘¨æœŸï¼Œéœ€è¦ç”¨åˆ°ä»¥ä¸‹å·¥å…·ï¼š\n",
    "\n",
    "1. è°ƒè¯• Prompt çš„ Playground\n",
    "2. æµ‹è¯•/éªŒè¯ç³»ç»Ÿçš„ç›¸å…³æŒ‡æ ‡\n",
    "3. æ•°æ®é›†ç®¡ç†\n",
    "4. å„ç§æŒ‡æ ‡ç›‘æ§ä¸ç»Ÿè®¡ï¼šè®¿é—®é‡ã€å“åº”æ—¶é•¿ã€Tokenè´¹ç­‰ç­‰\n",
    "\n",
    "æ ¹æ®è‡ªå·±çš„æŠ€æœ¯æ ˆï¼Œé€‰æ‹©ï¼š\n",
    "\n",
    "1. LangSmith: LangChain çš„åŸå§‹ç®¡ç†å¹³å°\n",
    "2. LangFuseï¼šå¼€æºå¹³å°ï¼Œæ”¯æŒ LangChain å’ŒåŸç”Ÿ OpenAI API\n",
    "3. Prompt Flowï¼šå¼€æºå¹³å°ï¼Œæ”¯æŒ Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd761c5-485c-4f1c-993c-990e13a1aca6",
   "metadata": {},
   "source": [
    "## ä½œä¸š\n",
    "\n",
    "é€‰æ‹©ä¸€ä¸ªå·¥å…·å¹³å°ï¼Œå¯¹è‡ªå·±ä¹‹å‰å¼€å‘çš„ç³»ç»Ÿæˆ–æ¨¡å‹åšæ‰¹é‡æµ‹è¯•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
